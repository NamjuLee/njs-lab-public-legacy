{"version":3,"file":"static/js/27716.28e368ec.chunk.js","mappings":"sKAIO,MAAMA,EACJC,UAEP,CACAC,YAAYC,GAUVC,GAGF,EAEF,MAAMA,EAAUC,UACd,MAAMC,QAAaC,IAEnBC,EAAQF,GAER,MAAMG,QAAeC,EAAgBJ,GAG/BK,EAAQC,UAERC,EAAWF,EAAOF,EAAOK,OAAQL,EAAOM,QAE9CC,EAAUL,EAAOL,EAAMG,EAAO,EAG1BF,EAAUF,UACd,MAAMY,QAAyBC,MAAM,+DAQrC,aAPuBD,EAAiBE,QACfC,KAAIC,IAAG,CAC9BC,IAAKD,EAAIE,iBACTC,WAAYH,EAAII,eAEfC,QAAOL,GAAmB,MAAXA,EAAIC,KAAiC,MAAlBD,EAAIG,YAE3B,EAGVhB,EAAUH,UACd,MAAMsB,EAASrB,EAAKc,KAAIQ,IAAC,CACvBC,EAAGD,EAAEJ,WACLM,EAAGF,EAAEN,QAGPS,EAAAA,OAAAA,YACE,CAAEC,KAAM,oBACR,CAAEL,UACF,CACEM,OAAQ,aACRC,OAAQ,MACRC,OAAQ,KAEX,EAIGvB,EAAc,KAElB,MAAMD,EAAQyB,EAAAA,aAQd,OALAzB,EAAM0B,IAAID,EAAAA,OAAAA,MAAgB,CAAEE,WAAY,CAAC,GAAIC,MAAO,EAAGC,SAAS,KAGhE7B,EAAM0B,IAAID,EAAAA,OAAAA,MAAgB,CAAEG,MAAO,EAAGC,SAAS,KAExC7B,CAAK,EAIRD,EAAkBL,SAIf+B,EAAAA,MAAQ,KAEbA,EAAAA,KAAAA,QAAgB9B,GAGhB,MAAMQ,EAASR,EAAKc,KAAIQ,GAAKA,EAAEJ,aACzBT,EAAST,EAAKc,KAAIQ,GAAKA,EAAEN,MAEzBmB,EAAcL,EAAAA,SAAYtB,EAAQ,CAACA,EAAO4B,OAAQ,IAClDC,EAAcP,EAAAA,SAAYrB,EAAQ,CAACA,EAAO2B,OAAQ,IAGlDE,EAAWH,EAAYI,MACvBC,EAAWL,EAAYM,MACvBC,EAAWL,EAAYE,MACvBI,EAAWN,EAAYI,MAK7B,MAAO,CACLjC,OAJuB2B,EAAYS,IAAIJ,GAAUK,IAAIP,EAASM,IAAIJ,IAKlE/B,OAJuB4B,EAAYO,IAAID,GAAUE,IAAIH,EAASE,IAAID,IAMlEL,WACAE,WACAE,WACAC,WACD,IAICpC,EAAaR,MAAOM,EAAOG,EAAQC,KAEvCJ,EAAMyC,QAAQ,CACZC,UAAWjB,EAAAA,MAAAA,OACXkB,KAAMlB,EAAAA,OAAAA,iBACNmB,QAAS,CAAC,SAMZ,aAAa5C,EAAM6C,IAAI1C,EAAQC,EAAQ,CACrC0C,UAJgB,GAKhBC,OAJa,GAKbC,SAAS,EACTC,UAAW7B,EAAAA,KAAAA,aACT,CAAEC,KAAM,wBACR,CAAC,OAAQ,OACT,CAAEG,OAAQ,IAAKyB,UAAW,CAAC,iBAE7B,EAGE5C,EAAY,CAACL,EAAOkD,EAAWC,KACnC,MAAM,SAAElB,EAAQ,SAAEE,EAAQ,SAAEG,EAAQ,SAAED,GAAac,GAK5CC,EAAIC,GAAS5B,EAAAA,MAAQ,KAE1B,MAAM2B,EAAK3B,EAAAA,SAAY,EAAG,EAAG,KACvB4B,EAAQrD,EAAMsD,QAAQF,EAAGG,QAAQ,CAAC,IAAK,KAEvCC,EAAWJ,EAAGK,IAAIxB,EAASM,IAAIJ,IAAWT,IAAIS,GAE9CuB,EAAcL,EAAMI,IAAIpB,EAASE,IAAID,IAAWZ,IAAIY,GAG1D,MAAO,CAACkB,EAASG,WAAYD,EAAYC,WAAW,IAIhDC,EAAkBC,MAAMC,KAAKV,GAAI3C,KAAI,CAACsD,EAAKC,KACxC,CAAE9C,EAAG6C,EAAK5C,EAAGkC,EAAMW,OAGtBC,EAAiBf,EAAUzC,KAAIQ,IAAC,CACpCC,EAAGD,EAAEJ,WAAYM,EAAGF,EAAEN,QAIxBS,EAAAA,OAAAA,YACE,CAAEC,KAAM,sCACR,CAAEL,OAAQ,CAACiD,EAAgBL,GAAkBM,OAAQ,CAAC,WAAY,cAClE,CACE5C,OAAQ,aACRC,OAAQ,MACRC,OAAQ,KAEX,C","sources":["njslab/Workshop/workshop-ml/03_MPGPrediction/index.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\r\nimport * as tfvis from '@tensorflow/tfjs-vis';\r\nimport '@tensorflow/tfjs-backend-webgl';\r\n\r\nexport class Solution {\r\n  public destroy() {\r\n\r\n  }\r\n  constructor(id: string) {\r\n    //  https://js.tensorflow.org/api/latest/\r\n//     console.log(\"Let's learn TF JS !!\");\r\n//     console.log(\"==============================\");\r\n\r\n    // const data  = await getData()\r\n\r\n    //   const model = createModel();\r\n    //   tfvis.show.modelSummary({name: 'Model Summary'}, model);\r\n\r\n    execute();\r\n\r\n//     console.log('Playground done!');\r\n  }\r\n};\r\nconst execute = async () => {\r\n  const data = await getData();\r\n  // console.log(data);\r\n  visData(data);\r\n\r\n  const tensor = await convertToTensor(data);\r\n  // console.log(tensor)\r\n\r\n  const model = createModel()\r\n\r\n  await trainModel(model, tensor.inputs, tensor.labels);\r\n\r\n  testModel(model, data, tensor);\r\n\r\n}\r\nconst getData = async () => {\r\n  const carsDataResponse = await fetch('https://storage.googleapis.com/tfjs-tutorials/carsData.json');\r\n  const carsData = await carsDataResponse.json();\r\n  const cleaned = carsData.map(car => ({\r\n    mpg: car.Miles_per_Gallon,\r\n    horsepower: car.Horsepower,\r\n  }))\r\n    .filter(car => (car.mpg != null && car.horsepower != null));\r\n\r\n  return cleaned;\r\n};\r\n\r\nconst visData = async (data) => {\r\n  const values = data.map(d => ({\r\n    x: d.horsepower,\r\n    y: d.mpg,\r\n  }));\r\n\r\n  tfvis.render.scatterplot(\r\n    { name: 'Horsepower v MPG' },\r\n    { values },\r\n    {\r\n      xLabel: 'Horsepower',\r\n      yLabel: 'MPG',\r\n      height: 300\r\n    }\r\n  );\r\n\r\n}\r\n\r\nconst createModel = () => {\r\n  // Create a sequential model\r\n  const model = tf.sequential();\r\n\r\n  // Add a single input layer\r\n  model.add(tf.layers.dense({ inputShape: [1], units: 1, useBias: true }));\r\n\r\n  // Add an output layer\r\n  model.add(tf.layers.dense({ units: 1, useBias: true }));\r\n\r\n  return model;\r\n}\r\n\r\n\r\nconst convertToTensor = async (data) => {\r\n  // Wrapping these calculations in a tidy will dispose any\r\n  // intermediate tensors.\r\n\r\n  return tf.tidy(() => {\r\n    // Step 1. Shuffle the data\r\n    tf.util.shuffle(data);\r\n\r\n    // Step 2. Convert data to Tensor\r\n    const inputs = data.map(d => d.horsepower)\r\n    const labels = data.map(d => d.mpg);\r\n\r\n    const inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);\r\n    const labelTensor = tf.tensor2d(labels, [labels.length, 1]);\r\n\r\n    //Step 3. Normalize the data to the range 0 - 1 using min-max scaling\r\n    const inputMax = inputTensor.max();\r\n    const inputMin = inputTensor.min();\r\n    const labelMax = labelTensor.max();\r\n    const labelMin = labelTensor.min();\r\n\r\n    const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));\r\n    const normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));\r\n\r\n    return {\r\n      inputs: normalizedInputs,\r\n      labels: normalizedLabels,\r\n      // Return the min/max bounds so we can use them later.\r\n      inputMax,\r\n      inputMin,\r\n      labelMax,\r\n      labelMin,\r\n    }\r\n  });\r\n}\r\n\r\nconst trainModel = async (model, inputs, labels) => {\r\n  // Prepare the model for training.\r\n  model.compile({\r\n    optimizer: tf.train.adam(),\r\n    loss: tf.losses.meanSquaredError,\r\n    metrics: ['mse'],\r\n  });\r\n\r\n  const batchSize = 32;\r\n  const epochs = 30;\r\n\r\n  return await model.fit(inputs, labels, {\r\n    batchSize,\r\n    epochs,\r\n    shuffle: true,\r\n    callbacks: tfvis.show.fitCallbacks(\r\n      { name: 'Training Performance' },\r\n      ['loss', 'mse'],\r\n      { height: 200, callbacks: ['onEpochEnd'] }\r\n    )\r\n  });\r\n}\r\n\r\nconst testModel = (model, inputData, normalizationData) => {\r\n  const { inputMax, inputMin, labelMin, labelMax } = normalizationData;\r\n\r\n  // Generate predictions for a uniform range of numbers between 0 and 1;\r\n  // We un-normalize the data by doing the inverse of the min-max scaling\r\n  // that we did earlier.\r\n  const [xs, preds] = tf.tidy(() => {\r\n\r\n    const xs = tf.linspace(0, 1, 100);\r\n    const preds = model.predict(xs.reshape([100, 1]));\r\n\r\n    const unNormXs = xs.mul(inputMax.sub(inputMin)).add(inputMin);\r\n\r\n    const unNormPreds = preds.mul(labelMax.sub(labelMin)).add(labelMin);\r\n\r\n    // Un-normalize the data\r\n    return [unNormXs.dataSync(), unNormPreds.dataSync()];\r\n  });\r\n\r\n\r\n  const predictedPoints = Array.from(xs).map((val, i) => {\r\n    return { x: val, y: preds[i] }\r\n  });\r\n\r\n  const originalPoints = inputData.map(d => ({\r\n    x: d.horsepower, y: d.mpg,\r\n  }));\r\n\r\n\r\n  tfvis.render.scatterplot(\r\n    { name: 'Model Predictions vs Original Data' },\r\n    { values: [originalPoints, predictedPoints], series: ['original', 'predicted'] },\r\n    {\r\n      xLabel: 'Horsepower',\r\n      yLabel: 'MPG',\r\n      height: 300\r\n    }\r\n  );\r\n}"],"names":["Solution","destroy","constructor","id","execute","async","data","getData","visData","tensor","convertToTensor","model","createModel","trainModel","inputs","labels","testModel","carsDataResponse","fetch","json","map","car","mpg","Miles_per_Gallon","horsepower","Horsepower","filter","values","d","x","y","tfvis","name","xLabel","yLabel","height","tf","add","inputShape","units","useBias","inputTensor","length","labelTensor","inputMax","max","inputMin","min","labelMax","labelMin","sub","div","compile","optimizer","loss","metrics","fit","batchSize","epochs","shuffle","callbacks","inputData","normalizationData","xs","preds","predict","reshape","unNormXs","mul","unNormPreds","dataSync","predictedPoints","Array","from","val","i","originalPoints","series"],"sourceRoot":""}
{"version":3,"file":"static/js/10086.c86db258.chunk.js","mappings":"mJAEO,MAAMA,EASTC,cAA8B,IAAlBC,EAAW,uDAAG,EAAC,KAP3BC,QAAyB,GAAG,KAC5BC,UAAI,OAEJC,OAAiB,EAAE,KACnBC,aAAuB,IAAK,KAC5BC,eAAS,EAGLC,KAAKH,OAASH,EACd,IAAK,IAAIO,EAAI,EAAGA,EAAI,IAAKA,EAAG,CACxB,MAAMC,EAASC,EAAAA,SAAYA,EAAAA,OAA2B,EAAhBC,KAAKC,SAAgB,IAE3DL,KAAKL,QAAQW,KAAKJ,EACtB,CACAF,KAAKJ,KAAOO,EAAAA,SAAYA,EAAAA,OAA2B,EAAhBC,KAAKC,SAAgB,IACxDL,KAAKD,UAAYI,EAAAA,MAAAA,KAAcH,KAAKF,aACxC,CACQS,UAAUC,GAId,OAFWA,EAAEC,IAAIT,KAAKL,QAAQ,IACzBe,IAAIV,KAAKJ,KAElB,CACQe,UAAUH,GAKd,OAHWA,EAAEI,SAASH,IAAIT,KAAKL,QAAQ,IAClCe,IAAIF,EAAEC,IAAIT,KAAKL,QAAQ,KACvBe,IAAIV,KAAKJ,KAElB,CACQiB,UAAUL,GAMd,OAJWA,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,IAC3Ce,IAAIF,EAAEI,SAASH,IAAIT,KAAKL,QAAQ,KAChCe,IAAIF,EAAEC,IAAIT,KAAKL,QAAQ,KACvBe,IAAIV,KAAKJ,KAElB,CACQmB,UAAUP,GAOd,OALWA,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,IAC3Ce,IAAIF,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,KACzCe,IAAIF,EAAEI,SAASH,IAAIT,KAAKL,QAAQ,KAChCe,IAAIF,EAAEC,IAAIT,KAAKL,QAAQ,KACvBe,IAAIV,KAAKJ,KAElB,CACQoB,UAAUR,GAQd,OANWA,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,IAC3Ce,IAAIF,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,KACzCe,IAAIF,EAAEM,IAAIX,EAAAA,OAAU,IAAIM,IAAIT,KAAKL,QAAQ,KACzCe,IAAIF,EAAEI,SAASH,IAAIT,KAAKL,QAAQ,KAChCe,IAAIF,EAAEC,IAAIT,KAAKL,QAAQ,KACvBe,IAAIV,KAAKJ,KAElB,CACQqB,cAAcT,GAClB,OAAoB,IAAhBR,KAAKH,OAAuBG,KAAKgB,UAAUR,GAC3B,IAAhBR,KAAKH,OAAuBG,KAAKe,UAAUP,GAC3B,IAAhBR,KAAKH,OAAuBG,KAAKa,UAAUL,GAC3B,IAAhBR,KAAKH,OAAuBG,KAAKW,UAAUH,IAC3CR,KAAKH,OAAuBG,KAAKO,UAAUC,GAEnD,CACOU,KAAKC,EAA0BC,GAClC,OAAOD,EAAKE,IAAID,GAAOR,SAASU,MACpC,CACA,cAAqBC,GACjB,MAAMC,EAAKrB,EAAAA,MAAQ,IACRH,KAAKiB,cAAcd,EAAAA,SAAYoB,MAG1C,IAAIE,EAAMD,EAAGE,WAEb,OADAF,EAAGG,UACIF,CACX,CACOG,MAAMC,EAAgBC,GAEzB3B,EAAAA,MAAQ,KACJ,MAAM4B,EAAK5B,EAAAA,SAAY0B,GACjBL,EAAKrB,EAAAA,SAAY2B,GACvB9B,KAAKD,UAAUiC,UAAS,IAAWhC,KAAKkB,KAAKlB,KAAKiB,cAAcc,GAAKP,IAAI,GAOjF,EC7FG,MAAMS,EAKTxC,cAAgB,KAHhByC,EAAY,EAAE,KACdtC,KAAe,CAIf,CACOuC,QAAQ3B,GACX,MAAMiB,EAAM,GACZ,IAAI,IAAIxB,EAAI,EAAGA,EAAIO,EAAE4B,SAAUnC,EAC3BwB,EAAInB,KAAKN,KAAKqC,aAAa7B,EAAEP,KAEjC,OAAOwB,CACX,CACQY,aAAa7B,GACjB,OAAOR,KAAKkC,EAAI1B,EAAIR,KAAKJ,IAC7B,CACO0C,IAAIC,EAAkBC,GACzB,IAAIC,EAAO,EACPC,EAAO,EACX,IAAK,IAAIzC,EAAI,EAAGA,EAAIsC,EAAMH,SAAUnC,EAChCwC,GAAQF,EAAMtC,GACdyC,GAAQF,EAAMvC,GAElB,IAAI0C,EAAQF,EAAOF,EAAMH,OACrBQ,EAAQF,EAAOH,EAAMH,OAErBS,EAAM,EACNC,EAAM,EACV,IAAK,IAAI7C,EAAI,EAAGA,EAAIsC,EAAMH,SAAUnC,EAChC4C,IAAQN,EAAMtC,GAAK0C,IAAUH,EAAMvC,GAAK2C,GACxCE,IAAQP,EAAMtC,GAAK0C,IAAUJ,EAAMtC,GAAK0C,GAE5C3C,KAAKkC,EAAIW,EAAMC,EACf9C,KAAKJ,KAAOgD,EAAQ5C,KAAKkC,EAAIS,CACjC,ECpCG,MAAMI,EAOTtD,cAAe,KALfuD,aAAuB,IAAK,KAC5BC,MAAgBC,OAAOC,iBAAiB,KACxCjD,OAAiB,EAAE,KACnBN,KAAe,CAIf,CACOuC,QAAQ3B,GACX,MAAMiB,EAAM,GACZ,IAAI,IAAIxB,EAAI,EAAGA,EAAIO,EAAE4B,SAAUnC,EAC3BwB,EAAInB,KAAKN,KAAKqC,aAAa7B,EAAEP,KAEjC,OAAOwB,CACX,CACQY,aAAa7B,GACjB,OAAOR,KAAKE,OAASM,EAAIR,KAAKJ,IAClC,CACOgC,MAAMW,EAAkBC,GAE3B,IAAK,IAAIvC,EAAI,EAAGA,EAAIsC,EAAMH,SAAUnC,EAAG,CACnC,IAAIO,EAAI+B,EAAMtC,GACVmD,EAAIZ,EAAMvC,GACVoD,EAAarD,KAAKE,OAASM,EAAIR,KAAKJ,KACxCI,KAAKiD,MAAQG,EAAIC,EAEjBrD,KAAKE,OAASF,KAAKE,OAAUF,KAAKiD,MAAQzC,EAAKR,KAAKgD,aACpDhD,KAAKJ,KAAOI,KAAKJ,KAAQI,KAAKiD,MAASjD,KAAKgD,YAEhD,CACJ,EC/BG,MAAMM,EAAiB/B,IAC1B,IAAIgC,EAAqB,GACrBC,EAAmBC,EAAUlC,GACjC,IAAK,IAAImC,KAAKnC,EAAQgC,EAASjD,MAAOoD,EAAIF,EAAO,KAAOA,EAAO,GAAKA,EAAO,KAC3E,OAAOD,CAAQ,EAUNE,EAAaE,IACtB,IAAIC,EAAcV,OAAOW,UAAeC,EAAcZ,OAAOa,UAC7D,IAAK,IAAIL,KAAKC,EAAkBC,EAAMF,IAAKE,EAAMF,GAASI,EAAMJ,IAAKI,EAAMJ,GAC3E,MAAO,CAACE,EAAKE,EAAI,ECVRE,EAAYC,UAOrB,MAAMzD,EAAI8C,EAAc,CAAC,EAAE,EAAE,IACvBF,EAAIE,EAAc,CAAC,GAAG,KAAK,KAE3BnC,EAAOmC,EAAc,CAAC,EAAE,EAAE,KAIrB,IAAIrB,GACZK,IAAI9B,EAAG4C,GAKV,MAAMc,EAAO,IAAInB,EACjB,IAAI,IAAI9C,EAAI,EAAGA,EAAI,MAASA,EAExB,GADAiE,EAAKtC,MAAMpB,EAAG4C,GACXnD,EAAI,MAAS,EAAG,OACCiE,EAAK/B,QAAQhB,EAEjC,CAMJ,MAAMgD,EAAK,IAAI3E,EAAqB,GACpC,IAAI,IAAIS,EAAI,EAAGA,EAAI,MAAQA,EAEvB,GADAkE,EAAGvC,MAAMpB,EAAG4C,GACTnD,EAAI,MAAQ,EAAG,OACEkE,EAAGhC,QAAQhB,EAE/B,OAEYgD,EAAGhC,QAAQhB,EAAK,C","sources":["njslab/Env/NJSLabSandboxData/Definition/ModelRegression/PolynomialRegression.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/JSLinearRegression.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/JSLinearRegressionGD.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/Utility.ts","njslab/Env/NJSLabSandboxData/Definition/TFjs/Lesson0Normal.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\r\n\r\nexport class PolynomialRegression {\r\n\r\n    weights: tf.Variable[] = [];\r\n    bias: tf.Variable;\r\n\r\n    degree: number = 3;\r\n    leraningRate: number = 0.02;\r\n    optimizer: tf.AdamOptimizer;\r\n\r\n    constructor(dim: number = 0) {\r\n        this.degree = dim;\r\n        for (let i = 0; i < 5; ++i) {\r\n            const weight = tf.variable(tf.scalar((Math.random() * 2) - 1));\r\n            // weight.print();\r\n            this.weights.push(weight);\r\n        }\r\n        this.bias = tf.variable(tf.scalar((Math.random() * 2) - 1));\r\n        this.optimizer = tf.train.adam(this.leraningRate);\r\n    }\r\n    private predict1d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.mul(this.weights[0])\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict2d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.square().mul(this.weights[1])\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict3d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(3)).mul(this.weights[2])\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict4d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(4)).mul(this.weights[3])\r\n            .add(x.pow(tf.scalar(3)).mul(this.weights[2]))\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict5d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(5)).mul(this.weights[4])\r\n            .add(x.pow(tf.scalar(4)).mul(this.weights[3]))\r\n            .add(x.pow(tf.scalar(3)).mul(this.weights[2]))\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predictResult(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        if (this.degree === 5) { return this.predict5d(x); }\r\n        if (this.degree === 4) { return this.predict4d(x); }\r\n        if (this.degree === 3) { return this.predict3d(x); }\r\n        if (this.degree === 2) { return this.predict2d(x); }\r\n        if (this.degree === 1) { return this.predict1d(x); }\r\n        return this.predict1d(x);\r\n    }\r\n    public loss(pred: tf.Tensor<tf.Rank>, label: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        return pred.sub(label).square().mean();\r\n    }\r\n    public async predict(data: number[]) {\r\n        const ys = tf.tidy(() => {\r\n            return this.predictResult(tf.tensor1d(data));\r\n        });\r\n\r\n        let out = ys.dataSync();\r\n        ys.dispose();\r\n        return out;\r\n    }\r\n    public train(xVal: number[], yVal: number[] ) {\r\n\r\n        tf.tidy(() => {\r\n            const xs = tf.tensor1d(xVal);\r\n            const ys = tf.tensor1d(yVal);\r\n            this.optimizer.minimize((): any => this.loss(this.predictResult(xs), ys));\r\n        });\r\n\r\n        // console.log(tf.memory().numTensors);\r\n        // console.log('b:', this.bias, ', w:', this.weights);\r\n        // this.bias.print();\r\n        // this.weights.print();\r\n    }\r\n    // public train(x: tf.Tensor, y: tf.Tensor) {\r\n    //     tf.tidy((): any => {\r\n    //         return this.optimizer.minimize((): any => {\r\n    //             return this.loss(this.predict(x), y);\r\n    //         });\r\n    //     });\r\n    // }\r\n}","export class JSLinearRegression  {\r\n\r\n    a: number = 1;\r\n    bias: number = 0;\r\n\r\n    constructor( ) {\r\n\r\n    }\r\n    public predict(x: number[]) {\r\n        const out = [];\r\n        for(let i = 0; i < x.length; ++i) {\r\n            out.push(this.predictByNum(x[i]));\r\n        }\r\n        return out;\r\n    }\r\n    private predictByNum(x: number) {\r\n        return this.a * x + this.bias;\r\n    }\r\n    public fit(xList: number[] , yList: number[]) {\r\n        let xSum = 0;\r\n        let ySum = 0;\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            xSum += xList[i];\r\n            ySum += yList[i];\r\n        }\r\n        let xMean = xSum / xList.length;\r\n        let yMean = ySum / xList.length;\r\n\r\n        let num = 0;\r\n        let den = 0;\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            num += (xList[i] - xMean) * (yList[i] - yMean);\r\n            den += (xList[i] - xMean) * (xList[i] - xMean);\r\n        }\r\n        this.a = num / den;\r\n        this.bias = yMean - this.a * xMean;\r\n    }\r\n}","export class JSLinearRegressionGD {\r\n\r\n    learningRate: number = 0.02;\r\n    error: number = Number.MAX_SAFE_INTEGER;\r\n    weight: number = 1;\r\n    bias: number = 0;\r\n\r\n    constructor() {\r\n\r\n    }\r\n    public predict(x: number[]) {\r\n        const out = [];\r\n        for(let i = 0; i < x.length; ++i) {\r\n            out.push(this.predictByNum(x[i]));\r\n        }\r\n        return out;\r\n    }\r\n    private predictByNum(x: number) {\r\n        return this.weight * x + this.bias;\r\n    }\r\n    public train(xList: number[] , yList: number[]) {\r\n\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            let x = xList[i];\r\n            let y = yList[i];\r\n            let hypothesis = this.weight * x + this.bias;\r\n            this.error = y - hypothesis;\r\n\r\n            this.weight = this.weight + (this.error * x) * this.learningRate;\r\n            this.bias = this.bias + (this.error) * this.learningRate;\r\n\r\n        }\r\n    }\r\n}","\r\nexport const getNormalized = (data: number[]) => {\r\n    let valueOut: number[] = [];\r\n    let domain: number[] = getDomain(data);\r\n    for (let d of data) { valueOut.push(((d - domain[0]) / (domain[1] - domain[0]))); }\r\n    return valueOut;\r\n}\r\nexport const remaps = (CValue: number[], OldMin: number, OldMax: number, NewMin: number, NewMax: number) => {\r\n    let temp: number[] = [];\r\n    for (let d of CValue) { temp.push(remap(d, OldMin, OldMax, NewMin, NewMax)); }\r\n    return temp;\r\n}\r\nexport const remap = (CValue: number, OldMin: number, OldMax: number, NewMin: number, NewMax: number) => {\r\n    return (((CValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin;\r\n}\r\nexport const getDomain = (doubleList: number[]) => {\r\n    let Min: number = Number.MAX_VALUE; let Max: number = Number.MIN_VALUE;\r\n    for (let d of doubleList) { if (Min > d) { Min = d; } if (Max < d) { Max = d; } }\r\n    return [Min, Max];\r\n}","import * as tf from '@tensorflow/tfjs';\r\nimport * as tfvis from '@tensorflow/tfjs-vis';\r\n\r\nimport { PolynomialRegression } from '../ModelRegression/PolynomialRegression';\r\nimport { JSLinearRegression } from '../ModelRegression/JSLinearRegression';\r\nimport { JSLinearRegressionGD } from '../ModelRegression/JSLinearRegressionGD';\r\nimport { getNormalized } from '../ModelRegression/Utility';\r\n\r\nexport const execution = async (div: HTMLElement) =>{\r\n\r\n//     console.log('from lesson 01 ',tf, tfvis);\r\n\r\n    // const x = [1, 3, 5];\r\n    // const y = [2, 6, 9];\r\n\r\n    const x = getNormalized([1,3,5]);\r\n    const y = getNormalized([10,11.5,12]);\r\n\r\n    const pred = getNormalized([1,3,5]);\r\n//     console.log('pred:' , pred);\r\n\r\n//     console.log(\"===============================================\");\r\n    const ln = new JSLinearRegression();\r\n    ln.fit(x, y);\r\n//     console.log('LinearRegression: ',ln.predict(pred));\r\n\r\n\r\n//     console.log(\"===============================================\");\r\n    const lnGD = new JSLinearRegressionGD();\r\n    for(let i = 0; i < 10000; ++i) {\r\n        lnGD.train(x, y);\r\n        if(i % 1000 === 0) {\r\n            let out = await lnGD.predict(pred);\r\n        //     console.log(`GD ${i} ,${out}, ${lnGD.error}`);\r\n        }\r\n    }\r\n//     console.log('LinearRegressionGD: ',lnGD.predict(pred));\r\n\r\n\r\n//     console.log(\"===============================================\");\r\n    const lg = new PolynomialRegression(1);\r\n    for(let i = 0; i < 2000; ++i) {\r\n        lg.train(x, y);\r\n        if(i % 400 === 0) {\r\n            let out = await lg.predict(pred);\r\n        //     console.log(out);\r\n        }\r\n    }\r\n    let out = await lg.predict(pred);\r\n//     console.log(`PolynomialRegression 1D ,${out}`);\r\n}\r\n"],"names":["PolynomialRegression","constructor","dim","weights","bias","degree","leraningRate","optimizer","this","i","weight","tf","Math","random","push","predict1d","x","mul","add","predict2d","square","predict3d","pow","predict4d","predict5d","predictResult","loss","pred","label","sub","mean","data","ys","out","dataSync","dispose","train","xVal","yVal","xs","minimize","JSLinearRegression","a","predict","length","predictByNum","fit","xList","yList","xSum","ySum","xMean","yMean","num","den","JSLinearRegressionGD","learningRate","error","Number","MAX_SAFE_INTEGER","y","hypothesis","getNormalized","valueOut","domain","getDomain","d","doubleList","Min","MAX_VALUE","Max","MIN_VALUE","execution","async","lnGD","lg"],"sourceRoot":""}